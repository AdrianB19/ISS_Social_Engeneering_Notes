\section{Technical languages}

\subsection{Common semantic dimensions}
We could see two different meanings according to dictionary. Social and political sciences use centralized planning in an attempt to manage social change and regulate the future development and behaviour of a society.
On the other hand, the use of deception is praticate to induce a person to divulge private information or exposing unauthorized access to an information system.
The common semantic dimensions are:
\begin{itemize}
    \item Epistemic asymmetry
    \item Technocratic dominance
    \item Teleological replacement
\end{itemize}

\paragraph{\textbf{Epistemic asymmetry:}}occurs when one person or group enjoys a significant advantage of knowledge over another person or group within a specific domain to which that knowledge applies.
\paragraph{\textbf{Technocratic dominance:}}occurs when a person or group possessing a high-degree of technical knowledge uses that knowledge to enact changes in the behavior of others, where such behaviors place those affected in a position of decreased power or authority relative to the former within the affected domain. One consequence of this in the STS domain is the so called «Knowledge deficit» model.
\paragraph{\textbf{Teleological replacement:}}occurs when person or group A manages to substitute, in individual or group B, the original purpose or goal of their behavior with that of A.  

\paragraph{Deception:}social performance, relies on trust rituals, impression management, symbolic manipulation. We must study how people interpret intentions, assess credibility and react under uncertainty. Induce implies persuasion, framing, and nudge techniques.

\noindent \\According to the Oxford English Dictionary, the term “Social Engieering” has two distinct meanings depending on the context in which it is used. In the field of social and political sciences, SE refers to the use of centralized planning as a strategy to manage social change and regulate the future development and behavior of a society. This involves guiding societal progress through structured decision-making and policy implementation. In contrast, within the realm of cyberspace, SE stands for the use of deception to manipulate individuals into revealing private information or providing unauthorized access to computer systems or networks. Despite these differences, both applications share common semantic dimensions identified by Hatfield 2017, including epistemic asymmetry, where one party possesses knowledge that others do not; technocratic dominance, reflecting control by experts or specialized systems, teleological replacement, which involves substituting one set of goals or processes with another to achieve desired outcomes. These shared dimensions highlight the underlying conceptual parallels between SE in social regulation and in cybersecurity, despite their different practical contexts.Social engineering used to be about political action to fix society ills.
\subsection{Cialdini's principles}
Robert Cialdini outlines six key principles of \textbf{persuasion} which are fundamental to understanding how social engineering tactics can be effective.
\paragraph{\textbf{Reciprocity}}The principle of \textbf{reciprocity} is based on the idea that individuals feel a natural obligation to return favours or concessions they have received. When someone performs a helpful action, offers support, or provides a small benefit, the recipient typically experiences social pressure---often unconscious---to reciprocate. In the context of social engineering, attackers exploit this psychological mechanism by offering small gifts, assistance, or seemingly valuable information. This creates a sense of indebtedness in the target, who may then feel compelled to ``give something back,'' potentially by disclosing sensitive or confidential information. Reciprocity thus becomes a powerful lever for manipulating behaviour and lowering a victim's resistance.
\paragraph{\textbf{Commitment and consistency}}The principle of \textbf{commitment and consistency} refers to the human tendency to align future behaviour with previous decisions or statements. Once individuals commit to something---especially if the commitment is explicit or public---they feel internal and social pressure to act in ways that remain consistent with that initial choice. This mechanism is frequently exploited in social engineering. An attacker may begin by eliciting a small, seemingly harmless agreement from the target. This initial compliance increases the likelihood that the target will later accept a larger request, a dynamic known as the \textit{foot-in-the-door} technique. By leveraging the desire for consistency, attackers gradually escalate their demands while reducing the victim's psychological resistance.
\paragraph{\textbf{Social proof}}The principle of \textbf{social proof} describes the human tendency to look to others when deciding how to behave, particularly in situations of uncertainty or ambiguity. When individuals observe that many people are performing a specific action, they often interpret that behaviour as appropriate or correct, relying on the group as a guide for their own decisions. Social engineers exploit this psychological mechanism by fabricating scenarios in which a behaviour appears widespread or commonly accepted. For example, an attacker may create the illusion that numerous users have already clicked on a particular link or followed a certain procedure. Faced with this perceived consensus, the target becomes more inclined to imitate the behaviour, lowering their guard and increasing the likelihood of compliance.
\paragraph{\textbf{Authority}}The principle of \textbf{authority} highlights the human tendency to comply with requests made by individuals perceived as legitimate authority figures. Titles, uniforms, professional roles, and other symbols of status significantly increase the likelihood that people will obey instructions without questioning them. Social engineers frequently exploit this psychological bias by impersonating authoritative roles, such as company executives, IT administrators, or security personnel. By presenting themselves as figures with institutional power or technical expertise, attackers reduce the target's resistance and create a context in which compliance feels both expected and justified. This manipulation enables them to extract sensitive information or gain unauthorized access with minimal scrutiny.
\paragraph{\textbf{Linking}}The principle of \textbf{liking} is grounded in the idea that people are more easily influenced by individuals they find appealing or relatable. Factors such as physical attractiveness, perceived similarity, genuine compliments, and a sense of familiarity all contribute to increasing interpersonal liking, which in turn enhances compliance. Social engineers routinely exploit this mechanism by deliberately building rapport with their targets. They may highlight shared interests, mirror the target's attitudes, or offer flattering remarks to create a positive emotional connection. Once the attacker is perceived as likable or trustworthy, the target becomes significantly more susceptible to influence, making it easier to extract information or persuade them to take harmful actions.
\paragraph{\textbf{Scarcity}}The principle of \textbf{scarcity} is rooted in the idea that people tend to assign greater value to things that appear limited or difficult to obtain. When an opportunity, resource, or piece of information is framed as scarce, individuals often experience a heightened sense of urgency and a fear of missing out, which can drive them to act more quickly and with less deliberation. Social engineers exploit this psychological bias by fabricating situations in which time, access, or availability seems restricted. For example, an attacker may claim that a particular offer, security update, or internal request is only available for a short period, pressuring the target into responding immediately. This artificially induced urgency reduces critical thinking and increases the likelihood of impulsive, risky decisions.

% old and new techniques
\subsection{Old and new Techniques}

\paragraph{Impersonation} 
May be used in an attempt to gather authentication information (e.g. usernames and passwords) to gain access to a targeted network. 
\paragraph{3RD Party Authorization}
Occurs when authentication details are stolen by or given to a third party
\paragraph{Phishing}
Attempt to trick the recipient into performing some action, usually clicking on a link or downloading an attachment, by masquerading as legitimate requests for information, security warnings, or normal e-mails from friends or co-workers.
\paragraph{Pop-ups}
Can be a potent tool for social engineering tactics due to their ability to appear unexpectedly and grab immediate attention.
\paragraph{Dumpster Diving} refers to searching through physical trash or recycling bins to recover sensitive information. This may include personal data (names, addresses, phone numbers, social security numbers) or corporate documents (internal memos, financial reports, strategic plans). \textit{Example: An attacker retrieves discarded employee records and uses them for identity theft or social engineering.}

\paragraph{Shoulder Surfing} involves observing someone over their shoulder to capture confidential information, such as PINs or passwords. Attackers may also record keystrokes using small cameras or direct observation. \textit{Example: While standing behind a person at an ATM, the attacker memorizes their PIN.}

\paragraph{In-Person Attack} includes physical presence tactics like impersonating staff or exploiting unattended workstations. These attacks rely on proximity and trust to gain unauthorized access. \textit{Example: An intruder enters a company office pretending to be IT support and accesses a logged-in terminal.}

\paragraph{Improper Use of Social Media} occurs when individuals share sensitive content online, use weak passwords, or neglect two-factor authentication. This can expose personal or professional details that attackers exploit. \textit{Example: A user posts a photo of their work badge on Instagram, revealing their full name and company ID.}

\paragraph{Internal Social Engineering} occurs when system administrators or internal security teams simulate attacks (e.g., phishing emails, spam) within their own organization. The goal is to identify vulnerable individuals and improve overall security awareness. This method helps expose weak points in the human element of cybersecurity. \textit{Example: A company sends fake phishing emails to its employees to test who clicks on malicious links, then provides targeted training to those who failed.}

\paragraph{Reverse Social Engineering} flips the traditional dynamic: instead of the attacker initiating contact, the victim is manipulated into reaching out to the attacker. This technique exploits trust and curiosity, often leveraging social media or misleading prompts. \textit{Example: An attacker posts online claiming to offer tech support for a common issue, prompting users to contact them and unknowingly share sensitive information.}

\paragraph{Automated Social Engineering} leverages botnets, algorithms, and automated programs to replicate traditional SE attacks at scale. These methods reduce the need for direct attacker-victim interaction and can target thousands of users simultaneously. \textit{Example: A botnet sends personalized phishing messages to employees across multiple companies, exploiting known vulnerabilities in email filters.}

\paragraph{Semantic Attacks} aim to deceive victims by manipulating the appearance or meaning of objects, rather than directly breaching systems. These attacks exploit trust and perception. \textit{Example: A spoofed website mimics a legitimate banking portal but is hosted on a malicious server. Victims enter their credentials, unknowingly handing them to the attacker.}

\paragraph{Sybil Attack} is a subtype of semantic attack where an attacker creates multiple fake identities on a social network. These personas are used to flood the platform with coordinated messages, giving the illusion of consensus. \textit{Example: An attacker uses dozens of fake profiles to promote misinformation, making it appear as the dominant viewpoint and suppressing dissent.}

\paragraph{Scareware} is another semantic tactic that frightens users into taking harmful actions. It typically presents fake alerts about malware infections and prompts users to download malicious software disguised as antivirus tools. \textit{Example: A pop-up claims “Your system is infected!” and urges the user to install a fake antivirus, which is actually spyware.}
